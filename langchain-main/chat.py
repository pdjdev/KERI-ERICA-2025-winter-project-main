"""
Simple RAG chatbot using ChromaDB + Google Gemini.
"""
import os
from dotenv import load_dotenv
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_chroma import Chroma
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough


def initialize_chatbot():
    """Initialize the RAG chatbot with ChromaDB and Gemini."""
    # Load environment variables
    load_dotenv()
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key or api_key.strip() == "":
        raise ValueError("GOOGLE_API_KEY is not set. Please add it to your .env file.")
    
    print("ğŸ”§ Initializing chatbot...")
    
    # Load embeddings
    embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    
    # Load existing ChromaDB
    vectorstore = Chroma(
        collection_name="my_rag_db",
        embedding_function=embeddings,
        persist_directory="./chroma_db"
    )
    print(f"âœ… Loaded ChromaDB from ./chroma_db")
    
    # Initialize Gemini LLM (use lite model for better availability)
    llm = ChatGoogleGenerativeAI(
        model="models/gemini-flash-lite-latest",
        temperature=0.7,
    )
    print(f"âœ… Initialized Gemini LLM (models/gemini-flash-lite-latest)")
    
    # Create retriever (smaller k to reduce token usage)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 2})
    
    # Create RAG prompt template
    template = """ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ "ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.

ì°¸ê³  ë¬¸ì„œ:
{context}

ì§ˆë¬¸: {question}

ë‹µë³€:"""
    
    prompt = ChatPromptTemplate.from_template(template)
    
    # Create RAG chain
    def format_docs(docs):
        return "\n\n".join([f"[ë¬¸ì„œ {i+1}]\n{doc.page_content}" for i, doc in enumerate(docs)])
    
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt
        | llm
        | StrOutputParser()
    )
    
    print("âœ… Chatbot ready!\n")
    return rag_chain, retriever


def chat_loop(rag_chain, retriever):
    """Run interactive chat loop."""
    print("=" * 70)
    print("ğŸ’¬ RAG Chatbot (ë¬¸ì„œ ê¸°ë°˜ ì§ˆë¬¸ë‹µë³€)")
    print("=" * 70)
    print("ğŸ“Œ ì—…ë¡œë“œëœ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.")
    print("ğŸ“Œ ì¢…ë£Œí•˜ë ¤ë©´ 'exit', 'quit', 'ì¢…ë£Œ' ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")
    
    while True:
        # Get user input
        user_input = input("ğŸ™‹ ì§ˆë¬¸: ").strip()
        
        # Check for exit commands
        if user_input.lower() in ["exit", "quit", "ì¢…ë£Œ", "ë‚˜ê°€ê¸°"]:
            print("\nğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ì•ˆë…•íˆ ê°€ì„¸ìš”!")
            break
        
        if not user_input:
            print("âš ï¸  ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n")
            continue
        
        # Get response from chatbot
        print("\nğŸ¤– ë‹µë³€ ìƒì„± ì¤‘...\n")
        try:
            # Get answer
            answer = rag_chain.invoke(user_input)
            
            # Get source documents
            source_docs = retriever.invoke(user_input)
            
            # Print answer
            print("=" * 70)
            print(f"ğŸ’¡ ë‹µë³€:\n{answer}")
            print("=" * 70)
            
            # Print sources (optional)
            if source_docs:
                print(f"\nğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ ({len(source_docs)}ê°œ):")
                for i, doc in enumerate(source_docs, 1):
                    preview = doc.page_content[:150].replace("\n", " ")
                    print(f"  [{i}] {preview}...")
            
            print("\n")
            
        except Exception as e:
            # Fallback: if quota/rate limit hit, return top retrieved chunks as answer
            err_msg = str(e)
            print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {err_msg}\n")
            if "RESOURCE_EXHAUSTED" in err_msg or "429" in err_msg:
                try:
                    source_docs = retriever.invoke(user_input)
                    if source_docs:
                        joined = "\n\n".join([doc.page_content for doc in source_docs])
                        print("=" * 70)
                        print("ğŸ’¡ LLM ì‚¬ìš© ì œí•œìœ¼ë¡œ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì§ì ‘ ë°˜í™˜í•©ë‹ˆë‹¤:")
                        print(joined[:1500])
                        print("=" * 70)
                        print(f"\nğŸ“š ì°¸ê³ í•œ ë¬¸ì„œ ({len(source_docs)}ê°œ):")
                        for i, doc in enumerate(source_docs, 1):
                            preview = doc.page_content[:150].replace("\n", " ")
                            print(f"  [{i}] {preview}...")
                        print("\n")
                    else:
                        print("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ì§ˆë¬¸ì„ ë” êµ¬ì²´ì ìœ¼ë¡œ ì…ë ¥í•´ë³´ì„¸ìš”.\n")
                except Exception as e2:
                    print(f"âŒ ëŒ€ì²´ ê²½ë¡œë„ ì‹¤íŒ¨: {e2}\n")


def main():
    """Main entry point."""
    try:
        rag_chain, retriever = initialize_chatbot()
        chat_loop(rag_chain, retriever)
    except Exception as e:
        print(f"\nâŒ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        print("ğŸ’¡ Tip: ./chroma_dbê°€ ì¡´ì¬í•˜ëŠ”ì§€, GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()
