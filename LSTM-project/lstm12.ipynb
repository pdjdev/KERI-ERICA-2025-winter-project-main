{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr  # 피어슨 상관계수 계산\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.modules.loss\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "num_of_try = 23\n",
    "num_epochs = 30\n",
    "learning_rate = 0.001\n",
    "num_folds = 5\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/parksung-cheol/Desktop/gambling_data/draw_based_lottery/draw_based_lottery.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m draw_based_lottery \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/parksung-cheol/Desktop/gambling_data/draw_based_lottery/draw_based_lottery.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m instant_lottery \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/parksung-cheol/Desktop/gambling_data/instant_lottery/instant_lottery.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m online_lottery \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/parksung-cheol/Desktop/gambling_data/online_lottery/online_lottery.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1706\u001b[0m     f,\n\u001b[1;32m   1707\u001b[0m     mode,\n\u001b[1;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1714\u001b[0m )\n\u001b[1;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.12/site-packages/pandas/io/common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    864\u001b[0m             handle,\n\u001b[1;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    869\u001b[0m         )\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/parksung-cheol/Desktop/gambling_data/draw_based_lottery/draw_based_lottery.csv'"
     ]
    }
   ],
   "source": [
    "draw_based_lottery = pd.read_csv('/Users/parksung-cheol/Desktop/논문/도박논문(국내)/gambling_data/draw_based_lottery/draw_based_lottery.csv')\n",
    "instant_lottery = pd.read_csv('/Users/parksung-cheol/Desktop/논문/도박논문(국내)/gambling_data/instant_lottery/instant_lottery.csv')\n",
    "online_lottery = pd.read_csv('/Users/parksung-cheol/Desktop/gambling_data/online_lottery/online_lottery.csv')\n",
    "pension_lottery = pd.read_csv('/Users/parksung-cheol/Desktop/gambling_data/pension_lottery/pension_lottery.csv')\n",
    "\n",
    "dataframes = [draw_based_lottery, instant_lottery, online_lottery,pension_lottery]\n",
    "\n",
    "lottery_all = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "lottery_all.sort_values(by=['User_ID'], inplace=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000</td>\n",
       "      <td>71</td>\n",
       "      <td>20</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00000</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00000</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009210</th>\n",
       "      <td>zzzzzzzzzzl</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>49000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009211</th>\n",
       "      <td>zzzzzzzzzzl</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>19000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009212</th>\n",
       "      <td>zzzzzzzzzzl</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009213</th>\n",
       "      <td>zzzzzzzzzzl</td>\n",
       "      <td>32</td>\n",
       "      <td>21</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23009214</th>\n",
       "      <td>zzzzzzzzzzl</td>\n",
       "      <td>33</td>\n",
       "      <td>9</td>\n",
       "      <td>8000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23009215 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              User_ID  Date  Time  Price\n",
       "0                0000    71    20   1000\n",
       "1                0000    66    23   1000\n",
       "2                0000    57    13   1000\n",
       "3               00000    12    12   5000\n",
       "4               00000    18    15   5000\n",
       "...               ...   ...   ...    ...\n",
       "23009210  zzzzzzzzzzl    32    21  49000\n",
       "23009211  zzzzzzzzzzl    33     9  19000\n",
       "23009212  zzzzzzzzzzl    47     2  75000\n",
       "23009213  zzzzzzzzzzl    32    21   2000\n",
       "23009214  zzzzzzzzzzl    33     9   8000\n",
       "\n",
       "[23009215 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lottery_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "merged_df = pd.read_csv('./final_all/final_all_lottery.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'F2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/new_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'F2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Total_Amount 컬럼 생성\u001b[39;00m\n\u001b[1;32m      2\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Amount\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mmerged_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mF2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF4\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF6\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF8\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Total_Amount 및 구매 금액 Feature에 로그 변환 적용\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF2\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF4\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF6\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mF8\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal_Amount\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/new_env/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/new_env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'F2'"
     ]
    }
   ],
   "source": [
    "# Total_Amount 컬럼 생성\n",
    "merged_df['Total_Amount'] = (\n",
    "    merged_df['F2'] + merged_df['F4'] + merged_df['F6'] + merged_df['F8']\n",
    ")\n",
    "\n",
    "# Total_Amount 및 구매 금액 Feature에 로그 변환 적용\n",
    "for col in ['F2', 'F4', 'F6', 'F8', 'Total_Amount']:\n",
    "    merged_df[col] = np.log1p(merged_df[col])  # log(1 + x)\n",
    "\n",
    "# Min-Max Scaling 적용\n",
    "feature_scaler = MinMaxScaler()\n",
    "target_scaler = MinMaxScaler()\n",
    "\n",
    "merged_df[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8']] = feature_scaler.fit_transform(\n",
    "    merged_df[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8']]\n",
    ")\n",
    "merged_df[['Total_Amount']] = target_scaler.fit_transform(merged_df[['Total_Amount']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    정규화된 MAE를 기반으로 Accuracy 계산\n",
    "    \"\"\"\n",
    "    mae = np.mean(np.abs(y_true - y_pred))  # 평균 절대 오차\n",
    "    mean_true = np.mean(y_true)  # 실제 값의 평균  \n",
    "    normalized_mae = mae / (mean_true + 1e-8)  # 정규화 (0으로 나누기 방지)\n",
    "    accuracy = 1 - normalized_mae\n",
    "    return max(0, accuracy) * 100 # Accuracy 하한을 0으로 제한\n",
    "\n",
    "# LSTM 모델 (Hidden layer 2개, Dropout 추가)\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim=8, hidden_dim=50, output_dim=1, num_layers=2, dropout=dropout):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)  # out: (batch_size, seq_len, hidden_dim)\n",
    "        out = out[:, -1, :]  # 마지막 타임스텝의 출력\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "# Sliding Window: 레이블을 7일 합계로 구함\n",
    "class LotteryDataset(Dataset):\n",
    "    def __init__(self, df, input_len=28, output_len=7):\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        user_groups = df.groupby('User_ID')\n",
    "        for _, group in user_groups:\n",
    "            group = group.sort_values(by='Date')\n",
    "            feature_data = group[['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8']].values\n",
    "            total_amount = group['Total_Amount'].values\n",
    "\n",
    "            for i in range(len(total_amount) - input_len - output_len + 1):\n",
    "                self.data.append(feature_data[i:i+input_len])\n",
    "                self.labels.append(total_amount[i+input_len:i+input_len+output_len].sum())  # 7일 합계\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.data[idx], dtype=torch.float32),\n",
    "            torch.tensor([self.labels[idx]], dtype=torch.float32)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수\n",
    "def evaluate_model(model, test_loader, device, target_scaler):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(all_targets)\n",
    "    y_pred = np.array(all_predictions)\n",
    "\n",
    "    # 역정규화\n",
    "    y_true_original = target_scaler.inverse_transform(y_true.reshape(-1, 1)).flatten()\n",
    "    y_pred_original = target_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # 평가 지표\n",
    "    mae = np.mean(np.abs(y_true_original - y_pred_original))\n",
    "    mse = mean_squared_error(y_true_original, y_pred_original)\n",
    "    r2 = r2_score(y_true_original, y_pred_original)\n",
    "    accuracy = calculate_accuracy(y_true_original, y_pred_original)\n",
    "    \n",
    "    # 피어슨 상관계수\n",
    "    pearson_corr, _ = pearsonr(y_true_original, y_pred_original)\n",
    "\n",
    "    return mae, mse, r2, accuracy, pearson_corr, y_true_original, y_pred_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'./final_all/LSTM/{num_of_try}', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 함수\n",
    "def plot_loss_per_epoch(train_losses, val_losses, filename=f\"./final_all/LSTM/{num_of_try}/loss_per_epoch.png\"):\n",
    "    plt.figure(figsize=(13, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', color='b', label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, marker='o', color='r', label='Validation Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(filename, dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_predictions_vs_actual(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/predictions_vs_actual.png\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_true, color='blue', label='Actual', alpha=0.7)\n",
    "    plt.plot(y_pred, color='red', label='Predicted', alpha=0.6)\n",
    "    plt.title('Actual vs Predicted')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Total Amount')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename, dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.8, color='black')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='red', linestyle='--', linewidth=3)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=17)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=17)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted2(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.8, color='purple')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='black', linestyle='--', linewidth=4)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=17)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=17)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted3(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=1, color='purple')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='green', linestyle='-', linewidth=3)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=20)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted4(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=1, color='purple')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='black', linestyle='-', linewidth=3)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=20)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted5(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=1, color='orange')  # 점 색상을 밝은 주황색으로 변경\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='black', linestyle='-', linewidth=3)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=20)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_txt(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/predictions.txt\"):\n",
    "    # Stack y_true and y_pred as columns\n",
    "    data = np.column_stack((y_true, y_pred))\n",
    "    # Save as a text file\n",
    "    np.savetxt(filename, data, fmt=\"%.6f\", delimiter=\"\\t\", header=\"y_true\\ty_pred\", comments=\"\")\n",
    "    print(f\"File saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "user_ids = merged_df['User_ID'].unique()\n",
    "train_user_ids, test_user_ids = train_test_split(user_ids, test_size=0.1, random_state=42)\n",
    "\n",
    "train_df = merged_df[merged_df['User_ID'].isin(train_user_ids)]\n",
    "test_df = merged_df[merged_df['User_ID'].isin(test_user_ids)]\n",
    "\n",
    "# Dataset 생성\n",
    "train_dataset = LotteryDataset(train_df)\n",
    "test_dataset = LotteryDataset(test_df)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가 (K-Fold)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "# best_r2 = float('-inf')\n",
    "best_p = float('-inf')\n",
    "best_model_state = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch 1/30 - Train Loss: 0.8404, Train Accuracy: 87.55%, Val Loss: 0.4337, Val Accuracy: 90.89%\n",
      "Epoch 2/30 - Train Loss: 0.4348, Train Accuracy: 90.81%, Val Loss: 0.4042, Val Accuracy: 91.35%\n",
      "Epoch 3/30 - Train Loss: 0.4140, Train Accuracy: 91.07%, Val Loss: 0.3789, Val Accuracy: 91.74%\n",
      "Epoch 4/30 - Train Loss: 0.4048, Train Accuracy: 91.18%, Val Loss: 0.3740, Val Accuracy: 91.61%\n",
      "Epoch 5/30 - Train Loss: 0.3970, Train Accuracy: 91.28%, Val Loss: 0.3892, Val Accuracy: 91.18%\n",
      "Epoch 6/30 - Train Loss: 0.3918, Train Accuracy: 91.35%, Val Loss: 0.3847, Val Accuracy: 91.49%\n",
      "Epoch 7/30 - Train Loss: 0.3863, Train Accuracy: 91.42%, Val Loss: 0.3741, Val Accuracy: 91.55%\n",
      "Epoch 8/30 - Train Loss: 0.3837, Train Accuracy: 91.46%, Val Loss: 0.3692, Val Accuracy: 91.51%\n",
      "Epoch 9/30 - Train Loss: 0.3793, Train Accuracy: 91.52%, Val Loss: 0.3550, Val Accuracy: 91.98%\n",
      "Epoch 10/30 - Train Loss: 0.3776, Train Accuracy: 91.54%, Val Loss: 0.3677, Val Accuracy: 91.61%\n",
      "Epoch 11/30 - Train Loss: 0.3750, Train Accuracy: 91.58%, Val Loss: 0.3575, Val Accuracy: 91.76%\n",
      "Epoch 12/30 - Train Loss: 0.3739, Train Accuracy: 91.58%, Val Loss: 0.3739, Val Accuracy: 91.50%\n",
      "Epoch 13/30 - Train Loss: 0.3707, Train Accuracy: 91.63%, Val Loss: 0.3612, Val Accuracy: 91.96%\n",
      "Epoch 14/30 - Train Loss: 0.3699, Train Accuracy: 91.63%, Val Loss: 0.3544, Val Accuracy: 91.87%\n",
      "Epoch 15/30 - Train Loss: 0.3694, Train Accuracy: 91.65%, Val Loss: 0.3580, Val Accuracy: 91.88%\n",
      "Epoch 16/30 - Train Loss: 0.3681, Train Accuracy: 91.66%, Val Loss: 0.3498, Val Accuracy: 92.04%\n",
      "Epoch 17/30 - Train Loss: 0.3667, Train Accuracy: 91.67%, Val Loss: 0.3663, Val Accuracy: 91.57%\n",
      "Epoch 18/30 - Train Loss: 0.3659, Train Accuracy: 91.69%, Val Loss: 0.3570, Val Accuracy: 91.85%\n",
      "Epoch 19/30 - Train Loss: 0.3654, Train Accuracy: 91.69%, Val Loss: 0.3577, Val Accuracy: 91.83%\n",
      "Epoch 20/30 - Train Loss: 0.3649, Train Accuracy: 91.70%, Val Loss: 0.3622, Val Accuracy: 91.68%\n",
      "Epoch 21/30 - Train Loss: 0.3636, Train Accuracy: 91.72%, Val Loss: 0.3532, Val Accuracy: 92.09%\n",
      "Epoch 22/30 - Train Loss: 0.3631, Train Accuracy: 91.73%, Val Loss: 0.3516, Val Accuracy: 92.06%\n",
      "Epoch 23/30 - Train Loss: 0.3621, Train Accuracy: 91.74%, Val Loss: 0.3533, Val Accuracy: 91.89%\n",
      "Epoch 24/30 - Train Loss: 0.3616, Train Accuracy: 91.74%, Val Loss: 0.3787, Val Accuracy: 91.41%\n",
      "Epoch 25/30 - Train Loss: 0.3606, Train Accuracy: 91.75%, Val Loss: 0.3617, Val Accuracy: 91.65%\n",
      "Epoch 26/30 - Train Loss: 0.3603, Train Accuracy: 91.75%, Val Loss: 0.3487, Val Accuracy: 92.03%\n",
      "Epoch 27/30 - Train Loss: 0.3594, Train Accuracy: 91.77%, Val Loss: 0.3439, Val Accuracy: 92.07%\n",
      "Epoch 28/30 - Train Loss: 0.3596, Train Accuracy: 91.77%, Val Loss: 0.3504, Val Accuracy: 91.96%\n",
      "Epoch 29/30 - Train Loss: 0.3582, Train Accuracy: 91.79%, Val Loss: 0.3550, Val Accuracy: 91.73%\n",
      "Epoch 30/30 - Train Loss: 0.3580, Train Accuracy: 91.79%, Val Loss: 0.3501, Val Accuracy: 91.98%\n",
      "Validation Results - MAE: 2.5534, MSE: 11.3829, R2: 0.8032, Accuracy: 91.98%, p score: 0.8970\n",
      "Fold 2/5\n",
      "Epoch 1/30 - Train Loss: 0.7926, Train Accuracy: 87.93%, Val Loss: 0.4773, Val Accuracy: 90.43%\n",
      "Epoch 2/30 - Train Loss: 0.4357, Train Accuracy: 90.83%, Val Loss: 0.4025, Val Accuracy: 91.23%\n",
      "Epoch 3/30 - Train Loss: 0.4135, Train Accuracy: 91.09%, Val Loss: 0.4074, Val Accuracy: 91.01%\n",
      "Epoch 4/30 - Train Loss: 0.4021, Train Accuracy: 91.24%, Val Loss: 0.4216, Val Accuracy: 91.19%\n",
      "Epoch 5/30 - Train Loss: 0.3936, Train Accuracy: 91.35%, Val Loss: 0.3990, Val Accuracy: 91.24%\n",
      "Epoch 6/30 - Train Loss: 0.3872, Train Accuracy: 91.43%, Val Loss: 0.3838, Val Accuracy: 91.46%\n",
      "Epoch 7/30 - Train Loss: 0.3819, Train Accuracy: 91.49%, Val Loss: 0.3905, Val Accuracy: 91.56%\n",
      "Epoch 8/30 - Train Loss: 0.3805, Train Accuracy: 91.52%, Val Loss: 0.3782, Val Accuracy: 91.60%\n",
      "Epoch 9/30 - Train Loss: 0.3762, Train Accuracy: 91.57%, Val Loss: 0.4010, Val Accuracy: 91.11%\n",
      "Epoch 10/30 - Train Loss: 0.3755, Train Accuracy: 91.57%, Val Loss: 0.4148, Val Accuracy: 90.94%\n",
      "Epoch 11/30 - Train Loss: 0.3730, Train Accuracy: 91.60%, Val Loss: 0.3767, Val Accuracy: 91.68%\n",
      "Epoch 12/30 - Train Loss: 0.3701, Train Accuracy: 91.64%, Val Loss: 0.3818, Val Accuracy: 91.43%\n",
      "Epoch 13/30 - Train Loss: 0.3692, Train Accuracy: 91.66%, Val Loss: 0.3762, Val Accuracy: 91.74%\n",
      "Epoch 14/30 - Train Loss: 0.3677, Train Accuracy: 91.68%, Val Loss: 0.3790, Val Accuracy: 91.61%\n",
      "Epoch 15/30 - Train Loss: 0.3660, Train Accuracy: 91.70%, Val Loss: 0.3685, Val Accuracy: 91.71%\n",
      "Epoch 16/30 - Train Loss: 0.3653, Train Accuracy: 91.71%, Val Loss: 0.4001, Val Accuracy: 91.12%\n",
      "Epoch 17/30 - Train Loss: 0.3641, Train Accuracy: 91.72%, Val Loss: 0.3744, Val Accuracy: 91.70%\n",
      "Epoch 18/30 - Train Loss: 0.3631, Train Accuracy: 91.74%, Val Loss: 0.3824, Val Accuracy: 91.65%\n",
      "Epoch 19/30 - Train Loss: 0.3612, Train Accuracy: 91.76%, Val Loss: 0.3845, Val Accuracy: 91.42%\n",
      "Epoch 20/30 - Train Loss: 0.3622, Train Accuracy: 91.76%, Val Loss: 0.3686, Val Accuracy: 91.72%\n",
      "Epoch 21/30 - Train Loss: 0.3606, Train Accuracy: 91.77%, Val Loss: 0.3856, Val Accuracy: 91.60%\n",
      "Epoch 22/30 - Train Loss: 0.3599, Train Accuracy: 91.78%, Val Loss: 0.3736, Val Accuracy: 91.76%\n",
      "Epoch 23/30 - Train Loss: 0.3598, Train Accuracy: 91.78%, Val Loss: 0.3671, Val Accuracy: 91.72%\n",
      "Epoch 24/30 - Train Loss: 0.3587, Train Accuracy: 91.80%, Val Loss: 0.3712, Val Accuracy: 91.63%\n",
      "Epoch 25/30 - Train Loss: 0.3577, Train Accuracy: 91.81%, Val Loss: 0.3683, Val Accuracy: 91.73%\n",
      "Epoch 26/30 - Train Loss: 0.3576, Train Accuracy: 91.81%, Val Loss: 0.3640, Val Accuracy: 91.79%\n",
      "Epoch 27/30 - Train Loss: 0.3570, Train Accuracy: 91.81%, Val Loss: 0.3662, Val Accuracy: 91.75%\n",
      "Epoch 28/30 - Train Loss: 0.3559, Train Accuracy: 91.83%, Val Loss: 0.3712, Val Accuracy: 91.60%\n",
      "Epoch 29/30 - Train Loss: 0.3556, Train Accuracy: 91.83%, Val Loss: 0.3671, Val Accuracy: 91.66%\n",
      "Epoch 30/30 - Train Loss: 0.3560, Train Accuracy: 91.83%, Val Loss: 0.3648, Val Accuracy: 91.80%\n",
      "Validation Results - MAE: 2.5876, MSE: 11.8607, R2: 0.7841, Accuracy: 91.80%, p score: 0.8857\n",
      "Fold 3/5\n",
      "Epoch 1/30 - Train Loss: 0.8765, Train Accuracy: 87.30%, Val Loss: 0.4469, Val Accuracy: 90.73%\n",
      "Epoch 2/30 - Train Loss: 0.4326, Train Accuracy: 90.86%, Val Loss: 0.4284, Val Accuracy: 91.16%\n",
      "Epoch 3/30 - Train Loss: 0.4125, Train Accuracy: 91.10%, Val Loss: 0.4038, Val Accuracy: 91.12%\n",
      "Epoch 4/30 - Train Loss: 0.4019, Train Accuracy: 91.25%, Val Loss: 0.3917, Val Accuracy: 91.24%\n",
      "Epoch 5/30 - Train Loss: 0.3933, Train Accuracy: 91.35%, Val Loss: 0.4188, Val Accuracy: 90.93%\n",
      "Epoch 6/30 - Train Loss: 0.3876, Train Accuracy: 91.43%, Val Loss: 0.3803, Val Accuracy: 91.54%\n",
      "Epoch 7/30 - Train Loss: 0.3844, Train Accuracy: 91.47%, Val Loss: 0.3839, Val Accuracy: 91.46%\n",
      "Epoch 8/30 - Train Loss: 0.3811, Train Accuracy: 91.51%, Val Loss: 0.3731, Val Accuracy: 91.61%\n",
      "Epoch 9/30 - Train Loss: 0.3775, Train Accuracy: 91.55%, Val Loss: 0.3754, Val Accuracy: 91.79%\n",
      "Epoch 10/30 - Train Loss: 0.3757, Train Accuracy: 91.58%, Val Loss: 0.4002, Val Accuracy: 91.09%\n",
      "Epoch 11/30 - Train Loss: 0.3736, Train Accuracy: 91.60%, Val Loss: 0.3694, Val Accuracy: 91.78%\n",
      "Epoch 12/30 - Train Loss: 0.3710, Train Accuracy: 91.64%, Val Loss: 0.3722, Val Accuracy: 91.55%\n",
      "Epoch 13/30 - Train Loss: 0.3703, Train Accuracy: 91.65%, Val Loss: 0.3754, Val Accuracy: 91.70%\n",
      "Epoch 14/30 - Train Loss: 0.3681, Train Accuracy: 91.68%, Val Loss: 0.3685, Val Accuracy: 91.61%\n",
      "Epoch 15/30 - Train Loss: 0.3675, Train Accuracy: 91.69%, Val Loss: 0.3927, Val Accuracy: 91.31%\n",
      "Epoch 16/30 - Train Loss: 0.3648, Train Accuracy: 91.72%, Val Loss: 0.3713, Val Accuracy: 91.51%\n",
      "Epoch 17/30 - Train Loss: 0.3648, Train Accuracy: 91.72%, Val Loss: 0.3678, Val Accuracy: 91.66%\n",
      "Epoch 18/30 - Train Loss: 0.3641, Train Accuracy: 91.73%, Val Loss: 0.3743, Val Accuracy: 91.73%\n",
      "Epoch 19/30 - Train Loss: 0.3628, Train Accuracy: 91.74%, Val Loss: 0.3909, Val Accuracy: 91.51%\n",
      "Epoch 20/30 - Train Loss: 0.3615, Train Accuracy: 91.76%, Val Loss: 0.3633, Val Accuracy: 91.77%\n",
      "Epoch 21/30 - Train Loss: 0.3608, Train Accuracy: 91.76%, Val Loss: 0.3777, Val Accuracy: 91.52%\n",
      "Epoch 22/30 - Train Loss: 0.3604, Train Accuracy: 91.77%, Val Loss: 0.3676, Val Accuracy: 91.77%\n",
      "Epoch 23/30 - Train Loss: 0.3595, Train Accuracy: 91.79%, Val Loss: 0.3661, Val Accuracy: 91.67%\n",
      "Epoch 24/30 - Train Loss: 0.3581, Train Accuracy: 91.80%, Val Loss: 0.3638, Val Accuracy: 91.77%\n",
      "Epoch 25/30 - Train Loss: 0.3578, Train Accuracy: 91.81%, Val Loss: 0.3615, Val Accuracy: 91.82%\n",
      "Epoch 26/30 - Train Loss: 0.3578, Train Accuracy: 91.81%, Val Loss: 0.3741, Val Accuracy: 91.58%\n",
      "Epoch 27/30 - Train Loss: 0.3575, Train Accuracy: 91.81%, Val Loss: 0.3694, Val Accuracy: 91.54%\n",
      "Epoch 28/30 - Train Loss: 0.3567, Train Accuracy: 91.83%, Val Loss: 0.3638, Val Accuracy: 91.80%\n",
      "Epoch 29/30 - Train Loss: 0.3557, Train Accuracy: 91.83%, Val Loss: 0.3743, Val Accuracy: 91.56%\n",
      "Epoch 30/30 - Train Loss: 0.3556, Train Accuracy: 91.83%, Val Loss: 0.4032, Val Accuracy: 91.49%\n",
      "Validation Results - MAE: 2.6873, MSE: 13.1109, R2: 0.7730, Accuracy: 91.49%, p score: 0.8916\n",
      "Fold 4/5\n",
      "Epoch 1/30 - Train Loss: 0.8101, Train Accuracy: 87.75%, Val Loss: 0.5216, Val Accuracy: 90.04%\n",
      "Epoch 2/30 - Train Loss: 0.4367, Train Accuracy: 90.82%, Val Loss: 0.4495, Val Accuracy: 90.41%\n",
      "Epoch 3/30 - Train Loss: 0.4170, Train Accuracy: 91.06%, Val Loss: 0.3883, Val Accuracy: 91.49%\n",
      "Epoch 4/30 - Train Loss: 0.4034, Train Accuracy: 91.23%, Val Loss: 0.3743, Val Accuracy: 91.64%\n",
      "Epoch 5/30 - Train Loss: 0.3968, Train Accuracy: 91.31%, Val Loss: 0.3830, Val Accuracy: 91.41%\n",
      "Epoch 6/30 - Train Loss: 0.3896, Train Accuracy: 91.40%, Val Loss: 0.3666, Val Accuracy: 91.75%\n",
      "Epoch 7/30 - Train Loss: 0.3842, Train Accuracy: 91.47%, Val Loss: 0.3653, Val Accuracy: 91.65%\n",
      "Epoch 8/30 - Train Loss: 0.3815, Train Accuracy: 91.51%, Val Loss: 0.3867, Val Accuracy: 91.27%\n",
      "Epoch 9/30 - Train Loss: 0.3788, Train Accuracy: 91.54%, Val Loss: 0.3658, Val Accuracy: 91.84%\n",
      "Epoch 10/30 - Train Loss: 0.3749, Train Accuracy: 91.60%, Val Loss: 0.3582, Val Accuracy: 91.81%\n",
      "Epoch 11/30 - Train Loss: 0.3724, Train Accuracy: 91.62%, Val Loss: 0.3753, Val Accuracy: 91.76%\n",
      "Epoch 12/30 - Train Loss: 0.3713, Train Accuracy: 91.64%, Val Loss: 0.3747, Val Accuracy: 91.50%\n",
      "Epoch 13/30 - Train Loss: 0.3692, Train Accuracy: 91.67%, Val Loss: 0.4061, Val Accuracy: 91.25%\n",
      "Epoch 14/30 - Train Loss: 0.3682, Train Accuracy: 91.68%, Val Loss: 0.3566, Val Accuracy: 91.79%\n",
      "Epoch 15/30 - Train Loss: 0.3670, Train Accuracy: 91.70%, Val Loss: 0.3596, Val Accuracy: 91.90%\n",
      "Epoch 16/30 - Train Loss: 0.3650, Train Accuracy: 91.72%, Val Loss: 0.3602, Val Accuracy: 91.69%\n",
      "Epoch 17/30 - Train Loss: 0.3636, Train Accuracy: 91.74%, Val Loss: 0.3724, Val Accuracy: 91.49%\n",
      "Epoch 18/30 - Train Loss: 0.3625, Train Accuracy: 91.75%, Val Loss: 0.3533, Val Accuracy: 91.93%\n",
      "Epoch 19/30 - Train Loss: 0.3622, Train Accuracy: 91.76%, Val Loss: 0.3636, Val Accuracy: 91.69%\n",
      "Epoch 20/30 - Train Loss: 0.3609, Train Accuracy: 91.77%, Val Loss: 0.3641, Val Accuracy: 91.63%\n",
      "Epoch 21/30 - Train Loss: 0.3606, Train Accuracy: 91.78%, Val Loss: 0.3554, Val Accuracy: 91.83%\n",
      "Epoch 22/30 - Train Loss: 0.3589, Train Accuracy: 91.79%, Val Loss: 0.3585, Val Accuracy: 91.73%\n",
      "Epoch 23/30 - Train Loss: 0.3590, Train Accuracy: 91.80%, Val Loss: 0.3704, Val Accuracy: 91.51%\n",
      "Epoch 24/30 - Train Loss: 0.3578, Train Accuracy: 91.81%, Val Loss: 0.3696, Val Accuracy: 91.77%\n",
      "Epoch 25/30 - Train Loss: 0.3581, Train Accuracy: 91.81%, Val Loss: 0.3525, Val Accuracy: 91.85%\n",
      "Epoch 26/30 - Train Loss: 0.3569, Train Accuracy: 91.83%, Val Loss: 0.3557, Val Accuracy: 91.82%\n",
      "Epoch 27/30 - Train Loss: 0.3566, Train Accuracy: 91.83%, Val Loss: 0.3588, Val Accuracy: 91.87%\n",
      "Epoch 28/30 - Train Loss: 0.3555, Train Accuracy: 91.84%, Val Loss: 0.3564, Val Accuracy: 91.74%\n",
      "Epoch 29/30 - Train Loss: 0.3561, Train Accuracy: 91.83%, Val Loss: 0.3708, Val Accuracy: 91.65%\n",
      "Epoch 30/30 - Train Loss: 0.3558, Train Accuracy: 91.84%, Val Loss: 0.3612, Val Accuracy: 91.87%\n",
      "Validation Results - MAE: 2.5693, MSE: 11.7327, R2: 0.7806, Accuracy: 91.87%, p score: 0.8851\n",
      "Fold 5/5\n",
      "Epoch 1/30 - Train Loss: 0.8419, Train Accuracy: 87.61%, Val Loss: 0.4615, Val Accuracy: 90.70%\n",
      "Epoch 2/30 - Train Loss: 0.4293, Train Accuracy: 90.92%, Val Loss: 0.4185, Val Accuracy: 91.03%\n",
      "Epoch 3/30 - Train Loss: 0.4070, Train Accuracy: 91.20%, Val Loss: 0.3949, Val Accuracy: 91.41%\n",
      "Epoch 4/30 - Train Loss: 0.3959, Train Accuracy: 91.34%, Val Loss: 0.4032, Val Accuracy: 91.28%\n",
      "Epoch 5/30 - Train Loss: 0.3880, Train Accuracy: 91.45%, Val Loss: 0.3833, Val Accuracy: 91.42%\n",
      "Epoch 6/30 - Train Loss: 0.3822, Train Accuracy: 91.51%, Val Loss: 0.4041, Val Accuracy: 90.95%\n",
      "Epoch 7/30 - Train Loss: 0.3778, Train Accuracy: 91.58%, Val Loss: 0.3831, Val Accuracy: 91.41%\n",
      "Epoch 8/30 - Train Loss: 0.3763, Train Accuracy: 91.59%, Val Loss: 0.3859, Val Accuracy: 91.42%\n",
      "Epoch 9/30 - Train Loss: 0.3732, Train Accuracy: 91.63%, Val Loss: 0.3794, Val Accuracy: 91.38%\n",
      "Epoch 10/30 - Train Loss: 0.3707, Train Accuracy: 91.66%, Val Loss: 0.3862, Val Accuracy: 91.50%\n",
      "Epoch 11/30 - Train Loss: 0.3686, Train Accuracy: 91.70%, Val Loss: 0.3728, Val Accuracy: 91.64%\n",
      "Epoch 12/30 - Train Loss: 0.3655, Train Accuracy: 91.73%, Val Loss: 0.3725, Val Accuracy: 91.52%\n",
      "Epoch 13/30 - Train Loss: 0.3647, Train Accuracy: 91.75%, Val Loss: 0.3802, Val Accuracy: 91.49%\n",
      "Epoch 14/30 - Train Loss: 0.3625, Train Accuracy: 91.77%, Val Loss: 0.3782, Val Accuracy: 91.50%\n",
      "Epoch 15/30 - Train Loss: 0.3626, Train Accuracy: 91.77%, Val Loss: 0.3758, Val Accuracy: 91.47%\n",
      "Epoch 16/30 - Train Loss: 0.3606, Train Accuracy: 91.80%, Val Loss: 0.3765, Val Accuracy: 91.39%\n",
      "Epoch 17/30 - Train Loss: 0.3604, Train Accuracy: 91.80%, Val Loss: 0.3699, Val Accuracy: 91.60%\n",
      "Epoch 18/30 - Train Loss: 0.3598, Train Accuracy: 91.80%, Val Loss: 0.3670, Val Accuracy: 91.66%\n",
      "Epoch 19/30 - Train Loss: 0.3580, Train Accuracy: 91.82%, Val Loss: 0.3702, Val Accuracy: 91.52%\n",
      "Epoch 20/30 - Train Loss: 0.3576, Train Accuracy: 91.83%, Val Loss: 0.3736, Val Accuracy: 91.64%\n",
      "Epoch 21/30 - Train Loss: 0.3562, Train Accuracy: 91.85%, Val Loss: 0.3826, Val Accuracy: 91.61%\n",
      "Epoch 22/30 - Train Loss: 0.3555, Train Accuracy: 91.86%, Val Loss: 0.3704, Val Accuracy: 91.69%\n",
      "Epoch 23/30 - Train Loss: 0.3550, Train Accuracy: 91.86%, Val Loss: 0.3863, Val Accuracy: 91.48%\n",
      "Epoch 24/30 - Train Loss: 0.3541, Train Accuracy: 91.88%, Val Loss: 0.3694, Val Accuracy: 91.73%\n",
      "Epoch 25/30 - Train Loss: 0.3551, Train Accuracy: 91.87%, Val Loss: 0.3731, Val Accuracy: 91.48%\n",
      "Epoch 26/30 - Train Loss: 0.3522, Train Accuracy: 91.91%, Val Loss: 0.3874, Val Accuracy: 91.38%\n",
      "Epoch 27/30 - Train Loss: 0.3526, Train Accuracy: 91.90%, Val Loss: 0.3690, Val Accuracy: 91.69%\n",
      "Epoch 28/30 - Train Loss: 0.3519, Train Accuracy: 91.90%, Val Loss: 0.3752, Val Accuracy: 91.48%\n",
      "Epoch 29/30 - Train Loss: 0.3513, Train Accuracy: 91.92%, Val Loss: 0.3684, Val Accuracy: 91.66%\n",
      "Epoch 30/30 - Train Loss: 0.3503, Train Accuracy: 91.92%, Val Loss: 0.3757, Val Accuracy: 91.48%\n",
      "Validation Results - MAE: 2.6804, MSE: 12.2047, R2: 0.7820, Accuracy: 91.48%, p score: 0.8846\n"
     ]
    }
   ],
   "source": [
    "fold_results=[]\n",
    "\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(train_user_ids):\n",
    "    print(f\"Fold {fold}/{num_folds}\")\n",
    "    fold_train_ids = train_user_ids[train_index]\n",
    "    fold_val_ids = train_user_ids[val_index]\n",
    "\n",
    "    fold_train_df = merged_df[merged_df['User_ID'].isin(fold_train_ids)]\n",
    "    fold_val_df = merged_df[merged_df['User_ID'].isin(fold_val_ids)]\n",
    "\n",
    "    fold_train_dataset = LotteryDataset(fold_train_df)\n",
    "    fold_val_dataset = LotteryDataset(fold_val_df)\n",
    "\n",
    "    fold_train_loader = DataLoader(fold_train_dataset, batch_size=32, shuffle=True)\n",
    "    fold_val_loader = DataLoader(fold_val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "    model = LSTMModel().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "    epoch_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        train_true = []\n",
    "        train_pred = []\n",
    "\n",
    "        # Training loop\n",
    "        for inputs, targets in fold_train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Collect predictions and true values for train accuracy\n",
    "            train_true.extend(targets.cpu().numpy())\n",
    "            train_pred.extend(outputs.cpu().detach().numpy())\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        avg_loss = epoch_loss / len(fold_train_loader)\n",
    "        epoch_losses.append(avg_loss)\n",
    "\n",
    "        # Calculate train accuracy\n",
    "        train_true_original = target_scaler.inverse_transform(np.array(train_true).reshape(-1, 1)).flatten()\n",
    "        train_pred_original = target_scaler.inverse_transform(np.array(train_pred).reshape(-1, 1)).flatten()\n",
    "        train_accuracy = calculate_accuracy(train_true_original, train_pred_original)\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in fold_val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Collect predictions and true values for validation accuracy\n",
    "                val_true.extend(targets.cpu().numpy())\n",
    "                val_pred.extend(outputs.cpu().detach().numpy())\n",
    "\n",
    "        avg_val_loss = val_loss / len(fold_val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Calculate validation accuracy\n",
    "        val_true_original = target_scaler.inverse_transform(np.array(val_true).reshape(-1, 1)).flatten()\n",
    "        val_pred_original = target_scaler.inverse_transform(np.array(val_pred).reshape(-1, 1)).flatten()\n",
    "        val_accuracy = calculate_accuracy(val_true_original, val_pred_original)\n",
    "\n",
    "        # Print metrics for the current epoch\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "            f\"Train Loss: {avg_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
    "            f\"Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\"\n",
    "        )\n",
    "\n",
    "    # Validation evaluation after all epochs\n",
    "    mae, mse, r2, accuracy, pearson_corr, _, _ = evaluate_model(model, fold_val_loader, device, target_scaler)\n",
    "    print(f\"Validation Results - MAE: {mae:.4f}, MSE: {mse:.4f}, R2: {r2:.4f}, Accuracy: {accuracy:.2f}%, p score: {pearson_corr:.4f}\")\n",
    "\n",
    "    # Fold 결과 저장\n",
    "    fold_results.append({\n",
    "        \"fold\": fold,\n",
    "        \"mae\": mae,\n",
    "        \"mse\": mse,\n",
    "        \"r2\": r2,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"pearson_corr\": pearson_corr\n",
    "    })\n",
    "\n",
    "    if pearson_corr > best_p:\n",
    "        best_p = pearson_corr\n",
    "        best_model_state = model.state_dict()\n",
    "\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Cross-Validation Results ===\n",
      "Fold 1 - MAE: 2.5534, MSE: 11.3829, R2: 0.8032, Accuracy: 91.98%, p score: 0.8970\n",
      "Fold 2 - MAE: 2.5876, MSE: 11.8607, R2: 0.7841, Accuracy: 91.80%, p score: 0.8857\n",
      "Fold 3 - MAE: 2.6873, MSE: 13.1109, R2: 0.7730, Accuracy: 91.49%, p score: 0.8916\n",
      "Fold 4 - MAE: 2.5693, MSE: 11.7327, R2: 0.7806, Accuracy: 91.87%, p score: 0.8851\n",
      "Fold 5 - MAE: 2.6804, MSE: 12.2047, R2: 0.7820, Accuracy: 91.48%, p score: 0.8846\n"
     ]
    }
   ],
   "source": [
    "# 전체 fold 결과 출력\n",
    "print(\"\\n=== Cross-Validation Results ===\")\n",
    "for result in fold_results:\n",
    "    print(\n",
    "        f\"Fold {result['fold']} - \"\n",
    "        f\"MAE: {result['mae']:.4f}, MSE: {result['mse']:.4f}, \"\n",
    "        f\"R2: {result['r2']:.4f}, Accuracy: {result['accuracy']:.2f}%, \"\n",
    "        f\"p score: {result['pearson_corr']:.4f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model saved to ./final_all/LSTM/models/model_23_best.pth with p score: 0.8970\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델 저장\n",
    "best_model_path = f'./final_all/LSTM/models/model_{num_of_try}_best.pth'\n",
    "torch.save(best_model_state, best_model_path)\n",
    "print(f'Best Model saved to {best_model_path} with p score: {best_p:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Results - MAE: 2.5765, MSE: 11.6240, R2: 0.7986, Accuracy: 91.87%, p score: 0.8941\n"
     ]
    }
   ],
   "source": [
    "# 최적 모델 로드 후 테스트 평가\n",
    "best_model = LSTMModel().to(device)\n",
    "best_model.load_state_dict(torch.load(best_model_path))\n",
    "mae, mse, r2, accuracy, pearson_corr, y_true_original, y_pred_original = evaluate_model(\n",
    "    best_model, test_loader, device, target_scaler\n",
    ")\n",
    "print(f'Test Results - MAE: {mae:.4f}, MSE: {mse:.4f}, R2: {r2:.4f}, Accuracy: {accuracy:.2f}%, p score: {pearson_corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss 시각화 저장\n",
    "plot_loss_per_epoch(epoch_losses, val_losses)\n",
    "\n",
    "# 예측값과 실제값 비교 시각화 저장\n",
    "plot_predictions_vs_actual(y_true_original, y_pred_original, filename=f\"./final_all/LSTM/{num_of_try}/predictions_vs_actual_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 plot 저장되었습니다.\n",
      "2번째 plot 저장되었습니다.\n",
      "3번째 plot 저장되었습니다.\n",
      "4번째 plot 저장되었습니다.\n",
      "5번째 plot 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 함수와 파일명을 리스트로 정의\n",
    "plot_functions = [\n",
    "    plot_scatter_actual_vs_predicted,\n",
    "    plot_scatter_actual_vs_predicted2,\n",
    "    plot_scatter_actual_vs_predicted3,\n",
    "    plot_scatter_actual_vs_predicted4,\n",
    "    plot_scatter_actual_vs_predicted5\n",
    "]\n",
    "\n",
    "# 반복문으로 각 함수 호출\n",
    "for i, plot_func in enumerate(plot_functions, start=1):\n",
    "    filename = f\"./final_all/LSTM/{num_of_try}/scatter_plot_test{i}.png\"\n",
    "    plot_func(y_true_original, y_pred_original, filename=filename)\n",
    "    print(f\"{i}번째 plot 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved to ./final_all/LSTM/23/predictions.txt\n"
     ]
    }
   ],
   "source": [
    "save_predictions_to_txt(y_true_original, y_pred_original, filename=f\"./final_all/LSTM/{num_of_try}/predictions.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
