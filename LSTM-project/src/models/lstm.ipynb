{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "823dd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, Optional\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "3af14991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch.nn.modules.loss\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "7e78f946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1196ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "    \n",
    "from src.utils.paths import DATASET_PATH\n",
    "from src.data.processing import preprocess_data, add_daily_features\n",
    "from src.features.fourier_transform import fft_features\n",
    "from src.dataset.windowing import build_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "86af4e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952c89fc",
   "metadata": {},
   "source": [
    "## 데이터 변환: 일자별로 F1~F48 컬럼 생성\n",
    "- F1: 0시 급속, F2: 0시 완속\n",
    "- F3: 1시 급속, F4: 1시 완속\n",
    "- ...\n",
    "- F47: 23시 급속, F48: 23시 완속"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "faff3c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F39</th>\n",
       "      <th>F40</th>\n",
       "      <th>F41</th>\n",
       "      <th>F42</th>\n",
       "      <th>F43</th>\n",
       "      <th>F44</th>\n",
       "      <th>F45</th>\n",
       "      <th>F46</th>\n",
       "      <th>F47</th>\n",
       "      <th>F48</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2800</td>\n",
       "      <td>700</td>\n",
       "      <td>3200</td>\n",
       "      <td>805</td>\n",
       "      <td>2320</td>\n",
       "      <td>791</td>\n",
       "      <td>1600</td>\n",
       "      <td>259</td>\n",
       "      <td>1520</td>\n",
       "      <td>...</td>\n",
       "      <td>8160</td>\n",
       "      <td>903</td>\n",
       "      <td>6880</td>\n",
       "      <td>1218</td>\n",
       "      <td>6080</td>\n",
       "      <td>1197</td>\n",
       "      <td>4360</td>\n",
       "      <td>1148</td>\n",
       "      <td>3800</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>1400</td>\n",
       "      <td>413</td>\n",
       "      <td>1240</td>\n",
       "      <td>413</td>\n",
       "      <td>1000</td>\n",
       "      <td>133</td>\n",
       "      <td>680</td>\n",
       "      <td>133</td>\n",
       "      <td>880</td>\n",
       "      <td>...</td>\n",
       "      <td>10040</td>\n",
       "      <td>1449</td>\n",
       "      <td>7800</td>\n",
       "      <td>1253</td>\n",
       "      <td>5600</td>\n",
       "      <td>1358</td>\n",
       "      <td>4800</td>\n",
       "      <td>1386</td>\n",
       "      <td>3840</td>\n",
       "      <td>1680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>2240</td>\n",
       "      <td>539</td>\n",
       "      <td>1480</td>\n",
       "      <td>525</td>\n",
       "      <td>1240</td>\n",
       "      <td>210</td>\n",
       "      <td>640</td>\n",
       "      <td>196</td>\n",
       "      <td>920</td>\n",
       "      <td>...</td>\n",
       "      <td>9160</td>\n",
       "      <td>1365</td>\n",
       "      <td>7640</td>\n",
       "      <td>1309</td>\n",
       "      <td>6080</td>\n",
       "      <td>1302</td>\n",
       "      <td>5520</td>\n",
       "      <td>1470</td>\n",
       "      <td>4880</td>\n",
       "      <td>2030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>2360</td>\n",
       "      <td>686</td>\n",
       "      <td>2040</td>\n",
       "      <td>364</td>\n",
       "      <td>1440</td>\n",
       "      <td>217</td>\n",
       "      <td>1160</td>\n",
       "      <td>217</td>\n",
       "      <td>1200</td>\n",
       "      <td>...</td>\n",
       "      <td>8080</td>\n",
       "      <td>980</td>\n",
       "      <td>6800</td>\n",
       "      <td>917</td>\n",
       "      <td>4880</td>\n",
       "      <td>1036</td>\n",
       "      <td>3880</td>\n",
       "      <td>987</td>\n",
       "      <td>4160</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>1640</td>\n",
       "      <td>469</td>\n",
       "      <td>1640</td>\n",
       "      <td>294</td>\n",
       "      <td>1280</td>\n",
       "      <td>294</td>\n",
       "      <td>920</td>\n",
       "      <td>175</td>\n",
       "      <td>1200</td>\n",
       "      <td>...</td>\n",
       "      <td>7400</td>\n",
       "      <td>1162</td>\n",
       "      <td>6640</td>\n",
       "      <td>1274</td>\n",
       "      <td>4960</td>\n",
       "      <td>1246</td>\n",
       "      <td>3680</td>\n",
       "      <td>952</td>\n",
       "      <td>2960</td>\n",
       "      <td>1057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>2024-09-26</td>\n",
       "      <td>2760</td>\n",
       "      <td>658</td>\n",
       "      <td>2240</td>\n",
       "      <td>378</td>\n",
       "      <td>1640</td>\n",
       "      <td>224</td>\n",
       "      <td>1200</td>\n",
       "      <td>182</td>\n",
       "      <td>2600</td>\n",
       "      <td>...</td>\n",
       "      <td>14480</td>\n",
       "      <td>2436</td>\n",
       "      <td>12240</td>\n",
       "      <td>1673</td>\n",
       "      <td>8480</td>\n",
       "      <td>1925</td>\n",
       "      <td>7600</td>\n",
       "      <td>1806</td>\n",
       "      <td>4560</td>\n",
       "      <td>1785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>3080</td>\n",
       "      <td>602</td>\n",
       "      <td>1800</td>\n",
       "      <td>588</td>\n",
       "      <td>1680</td>\n",
       "      <td>245</td>\n",
       "      <td>1760</td>\n",
       "      <td>161</td>\n",
       "      <td>2960</td>\n",
       "      <td>...</td>\n",
       "      <td>15080</td>\n",
       "      <td>2359</td>\n",
       "      <td>12560</td>\n",
       "      <td>1960</td>\n",
       "      <td>9360</td>\n",
       "      <td>1890</td>\n",
       "      <td>6640</td>\n",
       "      <td>1743</td>\n",
       "      <td>4880</td>\n",
       "      <td>1344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>3120</td>\n",
       "      <td>735</td>\n",
       "      <td>2080</td>\n",
       "      <td>714</td>\n",
       "      <td>2320</td>\n",
       "      <td>322</td>\n",
       "      <td>2120</td>\n",
       "      <td>245</td>\n",
       "      <td>3240</td>\n",
       "      <td>...</td>\n",
       "      <td>12760</td>\n",
       "      <td>1911</td>\n",
       "      <td>9760</td>\n",
       "      <td>1792</td>\n",
       "      <td>8240</td>\n",
       "      <td>1736</td>\n",
       "      <td>6440</td>\n",
       "      <td>1694</td>\n",
       "      <td>3520</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>2440</td>\n",
       "      <td>749</td>\n",
       "      <td>2240</td>\n",
       "      <td>434</td>\n",
       "      <td>1560</td>\n",
       "      <td>315</td>\n",
       "      <td>1520</td>\n",
       "      <td>259</td>\n",
       "      <td>2120</td>\n",
       "      <td>...</td>\n",
       "      <td>11160</td>\n",
       "      <td>1904</td>\n",
       "      <td>10280</td>\n",
       "      <td>1820</td>\n",
       "      <td>6400</td>\n",
       "      <td>1953</td>\n",
       "      <td>5720</td>\n",
       "      <td>1351</td>\n",
       "      <td>3520</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>1960</td>\n",
       "      <td>588</td>\n",
       "      <td>1800</td>\n",
       "      <td>154</td>\n",
       "      <td>1200</td>\n",
       "      <td>126</td>\n",
       "      <td>1240</td>\n",
       "      <td>133</td>\n",
       "      <td>2640</td>\n",
       "      <td>...</td>\n",
       "      <td>14400</td>\n",
       "      <td>2394</td>\n",
       "      <td>12240</td>\n",
       "      <td>1953</td>\n",
       "      <td>8800</td>\n",
       "      <td>1652</td>\n",
       "      <td>6840</td>\n",
       "      <td>1883</td>\n",
       "      <td>4280</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1735 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             일자    F1   F2    F3   F4    F5   F6    F7   F8    F9  ...    F39  \\\n",
       "0    2020-01-01  2800  700  3200  805  2320  791  1600  259  1520  ...   8160   \n",
       "1    2020-01-02  1400  413  1240  413  1000  133   680  133   880  ...  10040   \n",
       "2    2020-01-03  2240  539  1480  525  1240  210   640  196   920  ...   9160   \n",
       "3    2020-01-04  2360  686  2040  364  1440  217  1160  217  1200  ...   8080   \n",
       "4    2020-01-05  1640  469  1640  294  1280  294   920  175  1200  ...   7400   \n",
       "...         ...   ...  ...   ...  ...   ...  ...   ...  ...   ...  ...    ...   \n",
       "1730 2024-09-26  2760  658  2240  378  1640  224  1200  182  2600  ...  14480   \n",
       "1731 2024-09-27  3080  602  1800  588  1680  245  1760  161  2960  ...  15080   \n",
       "1732 2024-09-28  3120  735  2080  714  2320  322  2120  245  3240  ...  12760   \n",
       "1733 2024-09-29  2440  749  2240  434  1560  315  1520  259  2120  ...  11160   \n",
       "1734 2024-09-30  1960  588  1800  154  1200  126  1240  133  2640  ...  14400   \n",
       "\n",
       "       F40    F41   F42   F43   F44   F45   F46   F47   F48  \n",
       "0      903   6880  1218  6080  1197  4360  1148  3800  1078  \n",
       "1     1449   7800  1253  5600  1358  4800  1386  3840  1680  \n",
       "2     1365   7640  1309  6080  1302  5520  1470  4880  2030  \n",
       "3      980   6800   917  4880  1036  3880   987  4160  1477  \n",
       "4     1162   6640  1274  4960  1246  3680   952  2960  1057  \n",
       "...    ...    ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "1730  2436  12240  1673  8480  1925  7600  1806  4560  1785  \n",
       "1731  2359  12560  1960  9360  1890  6640  1743  4880  1344  \n",
       "1732  1911   9760  1792  8240  1736  6440  1694  3520  1645  \n",
       "1733  1904  10280  1820  6400  1953  5720  1351  3520   924  \n",
       "1734  2394  12240  1953  8800  1652  6840  1883  4280  1820  \n",
       "\n",
       "[1735 rows x 49 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.copy()\n",
    "\n",
    "df['일자'] = pd.to_datetime(df['일자'])\n",
    "\n",
    "fast_df = df[df['충전방식'] == '급속'].copy()\n",
    "slow_df = df[df['충전방식'] == '완속'].copy()\n",
    "\n",
    "hourly_cols = [f'{h}시' for h in range(24)]\n",
    "\n",
    "fast_df = fast_df.sort_values('일자').set_index('일자')[hourly_cols]\n",
    "slow_df = slow_df.sort_values('일자').set_index('일자')[hourly_cols]\n",
    "\n",
    "new_data = []\n",
    "\n",
    "all_dates = sorted(set(fast_df.index) | set(slow_df.index))\n",
    "\n",
    "for date in all_dates:\n",
    "    row = {'일자': date}\n",
    "    \n",
    "    for hour in range(24):\n",
    "        hour_col = f'{hour}시'\n",
    "        \n",
    "        f_idx_fast = hour * 2 + 1\n",
    "        if date in fast_df.index:\n",
    "            row[f'F{f_idx_fast}'] = fast_df.loc[date, hour_col]\n",
    "        else:\n",
    "            row[f'F{f_idx_fast}'] = 0\n",
    "        \n",
    "        f_idx_slow = hour * 2 + 2\n",
    "        if date in slow_df.index:\n",
    "            row[f'F{f_idx_slow}'] = slow_df.loc[date, hour_col]\n",
    "        else:\n",
    "            row[f'F{f_idx_slow}'] = 0\n",
    "    \n",
    "    new_data.append(row)\n",
    "\n",
    "df = pd.DataFrame(new_data)\n",
    "\n",
    "df = df.sort_values('일자').reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6f7bc4",
   "metadata": {},
   "source": [
    "## 일별 총 충전량 계산\n",
    "급속(홀수 F 컬럼)과 완속(짝수 F 컬럼)의 일별 합계 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "8b5bf0b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>daily_fast</th>\n",
       "      <th>daily_slow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>169120</td>\n",
       "      <td>16387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>155960</td>\n",
       "      <td>16240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>160400</td>\n",
       "      <td>18025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>152600</td>\n",
       "      <td>14357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>138520</td>\n",
       "      <td>15904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-01-06</td>\n",
       "      <td>144440</td>\n",
       "      <td>16814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>137000</td>\n",
       "      <td>17199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>155240</td>\n",
       "      <td>18781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>166680</td>\n",
       "      <td>18382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>168480</td>\n",
       "      <td>19201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          일자  daily_fast  daily_slow\n",
       "0 2020-01-01      169120       16387\n",
       "1 2020-01-02      155960       16240\n",
       "2 2020-01-03      160400       18025\n",
       "3 2020-01-04      152600       14357\n",
       "4 2020-01-05      138520       15904\n",
       "5 2020-01-06      144440       16814\n",
       "6 2020-01-07      137000       17199\n",
       "7 2020-01-08      155240       18781\n",
       "8 2020-01-09      166680       18382\n",
       "9 2020-01-10      168480       19201"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_cols = [f'F{i}' for i in range(1, 49, 2)]  # F1, F3, F5, ..., F47\n",
    "\n",
    "slow_cols = [f'F{i}' for i in range(2, 49, 2)]  # F2, F4, F6, ..., F48\n",
    "\n",
    "df['daily_fast'] = df[fast_cols].sum(axis=1)\n",
    "\n",
    "df['daily_slow'] = df[slow_cols].sum(axis=1)\n",
    "\n",
    "df[['일자', 'daily_fast', 'daily_slow']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe45044",
   "metadata": {},
   "source": [
    "## 로그 변환 (daily_fast, daily_slow)\n",
    "타겟 변수의 분포를 정규화하기 위해 ln(1+x) 변환 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "5e0bcc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 변환 전 원본 값 저장 (나중에 역변환 시 필요하면 사용)\n",
    "df['daily_fast_original'] = df['daily_fast'].copy()\n",
    "df['daily_slow_original'] = df['daily_slow'].copy()\n",
    "\n",
    "# ln(1+x) 변환 적용\n",
    "df['daily_fast'] = np.log1p(df['daily_fast'])\n",
    "df['daily_slow'] = np.log1p(df['daily_slow'])\n",
    "\n",
    "# F1~F48 모든 컬럼에 로그 변환 적용\n",
    "for i in range(1, 49):\n",
    "    df[f'F{i}'] = np.log1p(df[f'F{i}'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ab1e82",
   "metadata": {},
   "source": [
    "## MinMax Scaling (F1~F48)\n",
    "시간별 충전량 피처들을 0~1 범위로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "896c0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# F1~F48 컬럼 리스트\n",
    "feature_cols = [f'F{i}' for i in range(1, 49)]\n",
    "\n",
    "# MinMaxScaler 초기화\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# F1~F48 컬럼만 스케일링 (0~1 범위로 변환)\n",
    "df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "df[[\"daily_fast\"]] = scaler.fit_transform(df[[\"daily_fast\"]])\n",
    "df[[\"daily_slow\"]] = scaler.fit_transform(df[[\"daily_slow\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "0c864a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim=50, output_days=7, num_layers=2, dropout=dropout):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_dim: 입력 피처 차원 (48: F1~F48)\n",
    "            hidden_dim: LSTM 은닉층 크기\n",
    "            output_days: 예측할 일수 (7일)\n",
    "            num_layers: LSTM 레이어 수\n",
    "            dropout: 드롭아웃 비율\n",
    "        \"\"\"\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_days * 2)\n",
    "        self.output_days = output_days\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        \n",
    "        out = out[:, -1, :]\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        \n",
    "        out = out.view(-1, self.output_days, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "22af9270",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeriDataset(Dataset):\n",
    "    def __init__(self, df, input_len=28, output_len=7):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: 일자, F1~F48, daily_fast, daily_slow 컬럼을 가진 DataFrame\n",
    "            input_len: 입력으로 사용할 과거 일수 (기본 28일)\n",
    "            output_len: 예측할 미래 일수 (기본 7일)\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "\n",
    "        df = df.sort_values('일자').reset_index(drop=True)\n",
    "        \n",
    "        feature_cols = [f'F{i}' for i in range(1, 49)]\n",
    "        feature_data = df[feature_cols].values\n",
    "        \n",
    "        target_data = df[['daily_fast', 'daily_slow']].values\n",
    "        \n",
    "        for i in range(len(df) - input_len - output_len + 1):\n",
    "            self.data.append(feature_data[i:i+input_len])\n",
    "            \n",
    "            self.labels.append(target_data[i+input_len:i+input_len+output_len])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            torch.tensor(self.data[idx], dtype=torch.float32),      # (28, 48)\n",
    "            torch.tensor(self.labels[idx], dtype=torch.float32)     # (7, 2)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a551e0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 함수\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    정규화된 MAE를 기반으로 Accuracy 계산\n",
    "    \"\"\"\n",
    "    mae = np.mean(np.abs(y_true - y_pred))  # 평균 절대 오차\n",
    "    mean_true = np.mean(y_true)  # 실제 값의 평균  \n",
    "    normalized_mae = mae / (mean_true + 1e-8)  # 정규화 (0으로 나누기 방지)\n",
    "    accuracy = 1 - normalized_mae\n",
    "    return max(0, accuracy) * 100 # Accuracy 하한을 0으로 제한\n",
    "\n",
    "def evaluate_model(model, test_loader, device, target_scaler):\n",
    "    model.eval()\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_predictions.extend(outputs.cpu().numpy())\n",
    "\n",
    "    y_true = np.array(all_targets)\n",
    "    y_pred = np.array(all_predictions)\n",
    "\n",
    "    # 역정규화\n",
    "    y_true_original = target_scaler.inverse_transform(y_true.reshape(-1, 1)).flatten()\n",
    "    y_pred_original = target_scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # 평가 지표\n",
    "    mae = np.mean(np.abs(y_true_original - y_pred_original))\n",
    "    mse = mean_squared_error(y_true_original, y_pred_original)\n",
    "    r2 = r2_score(y_true_original, y_pred_original)\n",
    "    accuracy = calculate_accuracy(y_true_original, y_pred_original)\n",
    "    \n",
    "    # 피어슨 상관계수\n",
    "    pearson_corr, _ = pearsonr(y_true_original, y_pred_original)\n",
    "\n",
    "    return mae, mse, r2, accuracy, pearson_corr, y_true_original, y_pred_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "07ad9976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화 함수\n",
    "def plot_loss_per_epoch(train_losses, val_losses, filename=f\"./final_all/LSTM/{num_of_try}/loss_per_epoch.png\"):\n",
    "    plt.figure(figsize=(13, 6))\n",
    "    plt.plot(range(1, len(train_losses) + 1), train_losses, marker='o', color='b', label='Train Loss')\n",
    "    plt.plot(range(1, len(val_losses) + 1), val_losses, marker='o', color='r', label='Validation Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(filename, dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_predictions_vs_actual(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/predictions_vs_actual.png\"):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(y_true, color='blue', label='Actual', alpha=0.7)\n",
    "    plt.plot(y_pred, color='red', label='Predicted', alpha=0.6)\n",
    "    plt.title('Actual vs Predicted')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Total Amount')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename, dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.8, color='black')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='red', linestyle='--', linewidth=3)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=17)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=17)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted2(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=0.8, color='purple')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='black', linestyle='--', linewidth=4)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=17)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=17)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted3(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=1, color='purple')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='green', linestyle='-', linewidth=3)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=20)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted4(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=1, color='purple')\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='black', linestyle='-', linewidth=3)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=20)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()\n",
    "\n",
    "def plot_scatter_actual_vs_predicted5(y_true, y_pred, filename=f\"./final_all/LSTM/{num_of_try}/scatter_actual_vs_predicted.png\"):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.scatter(y_true, y_pred, alpha=1, color='orange')  # 점 색상을 밝은 주황색으로 변경\n",
    "    plt.plot([min(y_true), max(y_true)], [min(y_true), max(y_true)], color='black', linestyle='-', linewidth=3)\n",
    "    plt.title('Scatter Plot: Actual vs Predicted', fontsize=25)\n",
    "    plt.xlabel('Normalized Total Amount', fontsize=20)\n",
    "    plt.ylabel('Predicted Total Amount', fontsize=20)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=600)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "1f808ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>일자</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>...</th>\n",
       "      <th>F43</th>\n",
       "      <th>F44</th>\n",
       "      <th>F45</th>\n",
       "      <th>F46</th>\n",
       "      <th>F47</th>\n",
       "      <th>F48</th>\n",
       "      <th>daily_fast</th>\n",
       "      <th>daily_slow</th>\n",
       "      <th>daily_fast_original</th>\n",
       "      <th>daily_slow_original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>0.476517</td>\n",
       "      <td>0.766975</td>\n",
       "      <td>0.677947</td>\n",
       "      <td>0.824724</td>\n",
       "      <td>0.688053</td>\n",
       "      <td>0.972712</td>\n",
       "      <td>0.615550</td>\n",
       "      <td>0.774710</td>\n",
       "      <td>0.511685</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355517</td>\n",
       "      <td>0.341840</td>\n",
       "      <td>0.323789</td>\n",
       "      <td>0.339155</td>\n",
       "      <td>0.462554</td>\n",
       "      <td>0.394782</td>\n",
       "      <td>0.295880</td>\n",
       "      <td>0.229186</td>\n",
       "      <td>169120</td>\n",
       "      <td>16387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>0.212811</td>\n",
       "      <td>0.583023</td>\n",
       "      <td>0.309077</td>\n",
       "      <td>0.589453</td>\n",
       "      <td>0.432573</td>\n",
       "      <td>0.450154</td>\n",
       "      <td>0.386473</td>\n",
       "      <td>0.594698</td>\n",
       "      <td>0.317411</td>\n",
       "      <td>...</td>\n",
       "      <td>0.321714</td>\n",
       "      <td>0.423794</td>\n",
       "      <td>0.371812</td>\n",
       "      <td>0.463294</td>\n",
       "      <td>0.467406</td>\n",
       "      <td>0.662382</td>\n",
       "      <td>0.246932</td>\n",
       "      <td>0.222185</td>\n",
       "      <td>155960</td>\n",
       "      <td>16240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>0.391613</td>\n",
       "      <td>0.675831</td>\n",
       "      <td>0.377904</td>\n",
       "      <td>0.674008</td>\n",
       "      <td>0.497861</td>\n",
       "      <td>0.583687</td>\n",
       "      <td>0.370251</td>\n",
       "      <td>0.699354</td>\n",
       "      <td>0.333208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355517</td>\n",
       "      <td>0.396445</td>\n",
       "      <td>0.441625</td>\n",
       "      <td>0.502068</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.776542</td>\n",
       "      <td>0.263894</td>\n",
       "      <td>0.303211</td>\n",
       "      <td>160400</td>\n",
       "      <td>18025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>0.411468</td>\n",
       "      <td>0.759929</td>\n",
       "      <td>0.502758</td>\n",
       "      <td>0.544968</td>\n",
       "      <td>0.543252</td>\n",
       "      <td>0.593286</td>\n",
       "      <td>0.529435</td>\n",
       "      <td>0.726862</td>\n",
       "      <td>0.427647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265147</td>\n",
       "      <td>0.248041</td>\n",
       "      <td>0.265530</td>\n",
       "      <td>0.239604</td>\n",
       "      <td>0.504492</td>\n",
       "      <td>0.584702</td>\n",
       "      <td>0.233773</td>\n",
       "      <td>0.126429</td>\n",
       "      <td>152600</td>\n",
       "      <td>14357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>0.272998</td>\n",
       "      <td>0.627337</td>\n",
       "      <td>0.417840</td>\n",
       "      <td>0.469776</td>\n",
       "      <td>0.507498</td>\n",
       "      <td>0.682249</td>\n",
       "      <td>0.467376</td>\n",
       "      <td>0.668742</td>\n",
       "      <td>0.427647</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271830</td>\n",
       "      <td>0.367894</td>\n",
       "      <td>0.239097</td>\n",
       "      <td>0.215820</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>0.382919</td>\n",
       "      <td>0.175280</td>\n",
       "      <td>0.205940</td>\n",
       "      <td>138520</td>\n",
       "      <td>15904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>2024-09-26</td>\n",
       "      <td>0.471042</td>\n",
       "      <td>0.745395</td>\n",
       "      <td>0.539149</td>\n",
       "      <td>0.558260</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>0.602581</td>\n",
       "      <td>0.538512</td>\n",
       "      <td>0.679334</td>\n",
       "      <td>0.702565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492277</td>\n",
       "      <td>0.650422</td>\n",
       "      <td>0.601359</td>\n",
       "      <td>0.637731</td>\n",
       "      <td>0.547030</td>\n",
       "      <td>0.698952</td>\n",
       "      <td>0.599137</td>\n",
       "      <td>0.594253</td>\n",
       "      <td>279360</td>\n",
       "      <td>26215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>2024-09-27</td>\n",
       "      <td>0.512784</td>\n",
       "      <td>0.714375</td>\n",
       "      <td>0.454058</td>\n",
       "      <td>0.713958</td>\n",
       "      <td>0.590050</td>\n",
       "      <td>0.628825</td>\n",
       "      <td>0.641076</td>\n",
       "      <td>0.646231</td>\n",
       "      <td>0.748684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532863</td>\n",
       "      <td>0.638502</td>\n",
       "      <td>0.533904</td>\n",
       "      <td>0.614329</td>\n",
       "      <td>0.578455</td>\n",
       "      <td>0.527787</td>\n",
       "      <td>0.629507</td>\n",
       "      <td>0.566586</td>\n",
       "      <td>293760</td>\n",
       "      <td>25298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>2024-09-28</td>\n",
       "      <td>0.517694</td>\n",
       "      <td>0.783994</td>\n",
       "      <td>0.510313</td>\n",
       "      <td>0.782417</td>\n",
       "      <td>0.688053</td>\n",
       "      <td>0.708919</td>\n",
       "      <td>0.690923</td>\n",
       "      <td>0.759679</td>\n",
       "      <td>0.780830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.480475</td>\n",
       "      <td>0.583293</td>\n",
       "      <td>0.518627</td>\n",
       "      <td>0.595537</td>\n",
       "      <td>0.427092</td>\n",
       "      <td>0.649682</td>\n",
       "      <td>0.545902</td>\n",
       "      <td>0.525758</td>\n",
       "      <td>255800</td>\n",
       "      <td>24003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>2024-09-29</td>\n",
       "      <td>0.424152</td>\n",
       "      <td>0.790575</td>\n",
       "      <td>0.539149</td>\n",
       "      <td>0.606927</td>\n",
       "      <td>0.567552</td>\n",
       "      <td>0.702474</td>\n",
       "      <td>0.601813</td>\n",
       "      <td>0.774710</td>\n",
       "      <td>0.629985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.376601</td>\n",
       "      <td>0.659802</td>\n",
       "      <td>0.459403</td>\n",
       "      <td>0.446440</td>\n",
       "      <td>0.427092</td>\n",
       "      <td>0.301833</td>\n",
       "      <td>0.459945</td>\n",
       "      <td>0.497609</td>\n",
       "      <td>221880</td>\n",
       "      <td>23149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1734</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>0.340809</td>\n",
       "      <td>0.706170</td>\n",
       "      <td>0.454058</td>\n",
       "      <td>0.242510</td>\n",
       "      <td>0.487908</td>\n",
       "      <td>0.434374</td>\n",
       "      <td>0.547292</td>\n",
       "      <td>0.594698</td>\n",
       "      <td>0.707995</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507503</td>\n",
       "      <td>0.551078</td>\n",
       "      <td>0.548728</td>\n",
       "      <td>0.665248</td>\n",
       "      <td>0.517668</td>\n",
       "      <td>0.710666</td>\n",
       "      <td>0.585222</td>\n",
       "      <td>0.550072</td>\n",
       "      <td>273000</td>\n",
       "      <td>24766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1735 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             일자        F1        F2        F3        F4        F5        F6  \\\n",
       "0    2020-01-01  0.476517  0.766975  0.677947  0.824724  0.688053  0.972712   \n",
       "1    2020-01-02  0.212811  0.583023  0.309077  0.589453  0.432573  0.450154   \n",
       "2    2020-01-03  0.391613  0.675831  0.377904  0.674008  0.497861  0.583687   \n",
       "3    2020-01-04  0.411468  0.759929  0.502758  0.544968  0.543252  0.593286   \n",
       "4    2020-01-05  0.272998  0.627337  0.417840  0.469776  0.507498  0.682249   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "1730 2024-09-26  0.471042  0.745395  0.539149  0.558260  0.582734  0.602581   \n",
       "1731 2024-09-27  0.512784  0.714375  0.454058  0.713958  0.590050  0.628825   \n",
       "1732 2024-09-28  0.517694  0.783994  0.510313  0.782417  0.688053  0.708919   \n",
       "1733 2024-09-29  0.424152  0.790575  0.539149  0.606927  0.567552  0.702474   \n",
       "1734 2024-09-30  0.340809  0.706170  0.454058  0.242510  0.487908  0.434374   \n",
       "\n",
       "            F7        F8        F9  ...       F43       F44       F45  \\\n",
       "0     0.615550  0.774710  0.511685  ...  0.355517  0.341840  0.323789   \n",
       "1     0.386473  0.594698  0.317411  ...  0.321714  0.423794  0.371812   \n",
       "2     0.370251  0.699354  0.333208  ...  0.355517  0.396445  0.441625   \n",
       "3     0.529435  0.726862  0.427647  ...  0.265147  0.248041  0.265530   \n",
       "4     0.467376  0.668742  0.427647  ...  0.271830  0.367894  0.239097   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1730  0.538512  0.679334  0.702565  ...  0.492277  0.650422  0.601359   \n",
       "1731  0.641076  0.646231  0.748684  ...  0.532863  0.638502  0.533904   \n",
       "1732  0.690923  0.759679  0.780830  ...  0.480475  0.583293  0.518627   \n",
       "1733  0.601813  0.774710  0.629985  ...  0.376601  0.659802  0.459403   \n",
       "1734  0.547292  0.594698  0.707995  ...  0.507503  0.551078  0.548728   \n",
       "\n",
       "           F46       F47       F48  daily_fast  daily_slow  \\\n",
       "0     0.339155  0.462554  0.394782    0.295880    0.229186   \n",
       "1     0.463294  0.467406  0.662382    0.246932    0.222185   \n",
       "2     0.502068  0.578455  0.776542    0.263894    0.303211   \n",
       "3     0.239604  0.504492  0.584702    0.233773    0.126429   \n",
       "4     0.215820  0.346815  0.382919    0.175280    0.205940   \n",
       "...        ...       ...       ...         ...         ...   \n",
       "1730  0.637731  0.547030  0.698952    0.599137    0.594253   \n",
       "1731  0.614329  0.578455  0.527787    0.629507    0.566586   \n",
       "1732  0.595537  0.427092  0.649682    0.545902    0.525758   \n",
       "1733  0.446440  0.427092  0.301833    0.459945    0.497609   \n",
       "1734  0.665248  0.517668  0.710666    0.585222    0.550072   \n",
       "\n",
       "      daily_fast_original  daily_slow_original  \n",
       "0                  169120                16387  \n",
       "1                  155960                16240  \n",
       "2                  160400                18025  \n",
       "3                  152600                14357  \n",
       "4                  138520                15904  \n",
       "...                   ...                  ...  \n",
       "1730               279360                26215  \n",
       "1731               293760                25298  \n",
       "1732               255800                24003  \n",
       "1733               221880                23149  \n",
       "1734               273000                24766  \n",
       "\n",
       "[1735 rows x 53 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "689f55b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 데이터: 1461일 (2020-01-01 00:00:00 ~ 2023-12-31 00:00:00)\n",
      "Val 데이터: 182일 (2024-01-01 00:00:00 ~ 2024-06-30 00:00:00)\n",
      "Test 데이터: 92일 (2024-07-01 00:00:00 ~ 2024-09-30 00:00:00)\n"
     ]
    }
   ],
   "source": [
    "# 시간 기반 데이터 분리\n",
    "# Train: 2023-12-31까지, Val: 2024-01-01 ~ 2024-06-30, Test: 2024-07-01 ~ 2024-09-30\n",
    "\n",
    "train_df = df[df['일자'] <= '2023-12-31'].copy()\n",
    "val_df = df[(df['일자'] >= '2024-01-01') & (df['일자'] <= '2024-06-30')].copy()\n",
    "test_df = df[(df['일자'] >= '2024-07-01') & (df['일자'] <= '2024-09-30')].copy()\n",
    "\n",
    "print(f\"Train 데이터: {len(train_df)}일 ({train_df['일자'].min()} ~ {train_df['일자'].max()})\")\n",
    "print(f\"Val 데이터: {len(val_df)}일 ({val_df['일자'].min()} ~ {val_df['일자'].max()})\")\n",
    "print(f\"Test 데이터: {len(test_df)}일 ({test_df['일자'].min()} ~ {test_df['일자'].max()})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "bcae32c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset 샘플 수:\n",
      "  Train: 1427개\n",
      "  Val: 148개\n",
      "  Test: 58개\n"
     ]
    }
   ],
   "source": [
    "# Dataset 생성\n",
    "train_dataset = KeriDataset(train_df, input_len=28, output_len=7)\n",
    "val_dataset = KeriDataset(val_df, input_len=28, output_len=7)\n",
    "test_dataset = KeriDataset(test_df, input_len=28, output_len=7)\n",
    "\n",
    "print(f\"\\nDataset 샘플 수:\")\n",
    "print(f\"  Train: {len(train_dataset)}개\")\n",
    "print(f\"  Val: {len(val_dataset)}개\")\n",
    "print(f\"  Test: {len(test_dataset)}개\")\n",
    "\n",
    "# DataLoader 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c1bd73ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA 사용 가능: False\n",
      "CUDA 버전: None\n",
      "PyTorch 버전: 2.9.1+cpu\n",
      "⚠️ CUDA를 찾을 수 없습니다. CPU를 사용합니다.\n",
      "사용 Device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GPU 설정 확인\n",
    "print(\"CUDA 사용 가능:\", torch.cuda.is_available())\n",
    "print(\"CUDA 버전:\", torch.version.cuda)\n",
    "print(\"PyTorch 버전:\", torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU 이름:\", torch.cuda.get_device_name(0))\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"⚠️ CUDA를 찾을 수 없습니다. CPU를 사용합니다.\")\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f\"사용 Device: {device}\\n\")\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "54165948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Device: cpu\n",
      "Epochs: 100, Learning Rate: 0.001\n",
      "============================================================\n",
      "\n",
      "Epoch  5/100 | Train Loss: 0.004748 | Val Loss: 0.012930\n",
      "Epoch 10/100 | Train Loss: 0.003818 | Val Loss: 0.004641\n",
      "Epoch 15/100 | Train Loss: 0.003590 | Val Loss: 0.004427\n",
      "Epoch 20/100 | Train Loss: 0.003567 | Val Loss: 0.003931\n",
      "\n",
      "Early stopping at epoch 22\n",
      "\n",
      "학습 완료!\n",
      "최종 Train Loss: 0.003314\n",
      "최종 Val Loss: 0.005283\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 (GPU 활용)\n",
    "model = LSTMModel(input_dim=48, hidden_dim=100, output_days=7, num_layers=2, dropout=dropout)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Epochs: {num_epochs}, Learning Rate: {learning_rate}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    val_loss /= len(val_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch {epoch:2d}/{num_epochs} | Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f}\")\n",
    "    \n",
    "    # Early Stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "        model.load_state_dict(best_model_state)\n",
    "        break\n",
    "\n",
    "print(f\"\\n학습 완료!\")\n",
    "print(f\"최종 Train Loss: {train_losses[-1]:.6f}\")\n",
    "print(f\"최종 Val Loss: {val_losses[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "4d71e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터\n",
    "num_of_try = 23\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "num_folds = 5\n",
    "dropout = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "8776cc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics (scaled)\n",
      "MAE  : 0.067063\n",
      "RMSE : 0.085921\n",
      "MSE  : 0.007382\n",
      "R2   : -1.015467\n",
      "Accuracy (scaled): 88.84%\n",
      "\n",
      "Test Metrics (inverse-transformed, original units)\n",
      "MAE  (fast) : 26477.3750\n",
      "RMSE (fast) : 35913.0113\n",
      "MAE  (slow) : 2697.8350\n",
      "RMSE (slow) : 3168.8676\n",
      "MAE  (all)  : 14587.6055\n",
      "RMSE (all)  : 25493.0001\n",
      "R2   (all)  : 0.9619\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample predictions vs targets (first 10 steps, flattened):\n",
      "y_true=0.6535, y_pred=0.6202\n",
      "y_true=0.6299, y_pred=0.6653\n",
      "y_true=0.6770, y_pred=0.6484\n",
      "y_true=0.6495, y_pred=0.6796\n",
      "y_true=0.6831, y_pred=0.6471\n",
      "y_true=0.6464, y_pred=0.6852\n",
      "y_true=0.6990, y_pred=0.6487\n",
      "y_true=0.6848, y_pred=0.6983\n",
      "y_true=0.7208, y_pred=0.6531\n",
      "y_true=0.6283, y_pred=0.6982\n"
     ]
    }
   ],
   "source": [
    "# Test 평가 및 학습 곡선 플롯\n",
    "\n",
    "# Test 평가 (스케일된 값 기준)\n",
    "model.eval()\n",
    "all_targets = []\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        all_targets.append(targets.cpu().numpy())\n",
    "        all_preds.append(outputs.cpu().numpy())\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "y_true = np.concatenate(all_targets, axis=0)\n",
    "y_pred = np.concatenate(all_preds, axis=0)\n",
    "\n",
    "mae = mean_absolute_error(y_true.reshape(-1, 1), y_pred.reshape(-1, 1))\n",
    "mse = mean_squared_error(y_true.reshape(-1, 1), y_pred.reshape(-1, 1))\n",
    "rmse = mse ** 0.5\n",
    "r2 = r2_score(y_true.reshape(-1, 1), y_pred.reshape(-1, 1))\n",
    "accuracy = calculate_accuracy(y_true, y_pred)\n",
    "\n",
    "print(\"Test Metrics (scaled)\")\n",
    "print(f\"MAE  : {mae:.6f}\")\n",
    "print(f\"RMSE : {rmse:.6f}\")\n",
    "print(f\"MSE  : {mse:.6f}\")\n",
    "print(f\"R2   : {r2:.6f}\")\n",
    "print(f\"Accuracy (scaled): {accuracy:.2f}%\\n\")\n",
    "\n",
    "# --- 역변환 후 실제 단위 MAE/RMSE 계산 ---\n",
    "# 스케일러 재구성 (로그 변환된 타깃에 대해 MinMax 피팅)\n",
    "fast_log = np.log1p(df['daily_fast_original'].values.reshape(-1, 1))\n",
    "slow_log = np.log1p(df['daily_slow_original'].values.reshape(-1, 1))\n",
    "scaler_fast = MinMaxScaler().fit(fast_log)\n",
    "scaler_slow = MinMaxScaler().fit(slow_log)\n",
    "\n",
    "# 스케일된 예측/정답 분리\n",
    "true_fast_scaled = y_true[:, :, 0]\n",
    "true_slow_scaled = y_true[:, :, 1]\n",
    "pred_fast_scaled = y_pred[:, :, 0]\n",
    "pred_slow_scaled = y_pred[:, :, 1]\n",
    "\n",
    "# 역스케일링 후 원 단위 복원\n",
    "true_fast_log = scaler_fast.inverse_transform(true_fast_scaled.reshape(-1, 1)).reshape(true_fast_scaled.shape)\n",
    "pred_fast_log = scaler_fast.inverse_transform(pred_fast_scaled.reshape(-1, 1)).reshape(pred_fast_scaled.shape)\n",
    "true_slow_log = scaler_slow.inverse_transform(true_slow_scaled.reshape(-1, 1)).reshape(true_slow_scaled.shape)\n",
    "pred_slow_log = scaler_slow.inverse_transform(pred_slow_scaled.reshape(-1, 1)).reshape(pred_slow_scaled.shape)\n",
    "\n",
    "true_fast_orig = np.expm1(true_fast_log)\n",
    "pred_fast_orig = np.expm1(pred_fast_log)\n",
    "true_slow_orig = np.expm1(true_slow_log)\n",
    "pred_slow_orig = np.expm1(pred_slow_log)\n",
    "\n",
    "# 채널별 및 전체 지표\n",
    "mae_fast_orig = mean_absolute_error(true_fast_orig.flatten(), pred_fast_orig.flatten())\n",
    "rmse_fast_orig = mean_squared_error(true_fast_orig.flatten(), pred_fast_orig.flatten()) ** 0.5\n",
    "mae_slow_orig = mean_absolute_error(true_slow_orig.flatten(), pred_slow_orig.flatten())\n",
    "rmse_slow_orig = mean_squared_error(true_slow_orig.flatten(), pred_slow_orig.flatten()) ** 0.5\n",
    "\n",
    "true_all_orig = np.concatenate([true_fast_orig.flatten(), true_slow_orig.flatten()])\n",
    "pred_all_orig = np.concatenate([pred_fast_orig.flatten(), pred_slow_orig.flatten()])\n",
    "mae_all_orig = mean_absolute_error(true_all_orig, pred_all_orig)\n",
    "rmse_all_orig = mean_squared_error(true_all_orig, pred_all_orig) ** 0.5\n",
    "r2_all_orig = r2_score(true_all_orig, pred_all_orig)\n",
    "\n",
    "print(\"Test Metrics (inverse-transformed, original units)\")\n",
    "print(f\"MAE  (fast) : {mae_fast_orig:.4f}\")\n",
    "print(f\"RMSE (fast) : {rmse_fast_orig:.4f}\")\n",
    "print(f\"MAE  (slow) : {mae_slow_orig:.4f}\")\n",
    "print(f\"RMSE (slow) : {rmse_slow_orig:.4f}\")\n",
    "print(f\"MAE  (all)  : {mae_all_orig:.4f}\")\n",
    "print(f\"RMSE (all)  : {rmse_all_orig:.4f}\")\n",
    "print(f\"R2   (all)  : {r2_all_orig:.4f}\\n\")\n",
    "\n",
    "# 학습/검증 손실 곡선\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(val_losses, label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training / Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 예측 vs 실제 (첫 10개 타임스텝 예시)\n",
    "print(\"Sample predictions vs targets (first 10 steps, flattened):\")\n",
    "for i in range(min(10, len(y_true.flatten()))):\n",
    "    print(f\"y_true={y_true.flatten()[i]:.4f}, y_pred={y_pred.flatten()[i]:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
